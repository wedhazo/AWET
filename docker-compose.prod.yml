name: awet

x-logging: &default-logging
  driver: json-file
  options:
    max-size: "10m"
    max-file: "5"

x-security: &default-security
  init: true
  restart: unless-stopped
  security_opt:
    - no-new-privileges:true

services:
  kafka:
    image: confluentinc/cp-kafka:7.6.1
    container_name: kafka
    <<: *default-security
    ports:
      - "127.0.0.1:9092:9092"
      - "127.0.0.1:9101:9101"
    environment:
      KAFKA_NODE_ID: 1
      KAFKA_PROCESS_ROLES: broker,controller
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: CONTROLLER:PLAINTEXT,PLAINTEXT:PLAINTEXT,PLAINTEXT_HOST:PLAINTEXT
      KAFKA_LISTENERS: PLAINTEXT://kafka:29092,CONTROLLER://kafka:29093,PLAINTEXT_HOST://0.0.0.0:9092
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka:29092,PLAINTEXT_HOST://${KAFKA_EXTERNAL_ADVERTISED_LISTENER:?Set KAFKA_EXTERNAL_ADVERTISED_LISTENER}
      KAFKA_INTER_BROKER_LISTENER_NAME: PLAINTEXT
      KAFKA_CONTROLLER_LISTENER_NAMES: CONTROLLER
      KAFKA_CONTROLLER_QUORUM_VOTERS: 1@kafka:29093
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
      KAFKA_GROUP_INITIAL_REBALANCE_DELAY_MS: 0
      KAFKA_TRANSACTION_STATE_LOG_MIN_ISR: 1
      KAFKA_TRANSACTION_STATE_LOG_REPLICATION_FACTOR: 1
      KAFKA_MIN_INSYNC_REPLICAS: 1
      KAFKA_LOG_DIRS: /var/lib/kafka/data
      KAFKA_AUTO_CREATE_TOPICS_ENABLE: "false"
      KAFKA_JMX_PORT: 9101
      KAFKA_JMX_HOSTNAME: localhost
      CLUSTER_ID: ${KAFKA_CLUSTER_ID:?Set KAFKA_CLUSTER_ID}
    volumes:
      - kafka_data:/var/lib/kafka/data
    healthcheck:
      test: ["CMD-SHELL", "kafka-broker-api-versions --bootstrap-server localhost:9092 > /dev/null 2>&1"]
      interval: 15s
      timeout: 10s
      retries: 10
      start_period: 40s
    logging: *default-logging
    networks:
      - awet

  schema-registry:
    image: confluentinc/cp-schema-registry:7.6.1
    container_name: schema-registry
    <<: *default-security
    depends_on:
      kafka:
        condition: service_healthy
    ports:
      - "127.0.0.1:8081:8081"
    environment:
      SCHEMA_REGISTRY_KAFKASTORE_BOOTSTRAP_SERVERS: kafka:29092
      SCHEMA_REGISTRY_HOST_NAME: schema-registry
      SCHEMA_REGISTRY_LISTENERS: http://0.0.0.0:8081
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8081/subjects"]
      interval: 15s
      timeout: 5s
      retries: 10
      start_period: 20s
    logging: *default-logging
    networks:
      - awet

  kafka-ui:
    image: provectuslabs/kafka-ui:v0.7.2
    container_name: kafka-ui
    <<: *default-security
    profiles: ["ops"]
    depends_on:
      kafka:
        condition: service_healthy
      schema-registry:
        condition: service_healthy
    ports:
      - "127.0.0.1:8080:8080"
    environment:
      KAFKA_CLUSTERS_0_NAME: awet
      KAFKA_CLUSTERS_0_BOOTSTRAPSERVERS: kafka:29092
      KAFKA_CLUSTERS_0_SCHEMAREGISTRY: http://schema-registry:8081
    healthcheck:
      test: ["CMD", "wget", "--spider", "-q", "http://localhost:8080"]
      interval: 20s
      timeout: 5s
      retries: 10
    logging: *default-logging
    networks:
      - awet

  timescaledb:
    image: timescale/timescaledb:2.13.1-pg15
    container_name: timescaledb
    <<: *default-security
    ports:
      - "127.0.0.1:5433:5432"
    environment:
      POSTGRES_DB: awet
      POSTGRES_USER: awet
      POSTGRES_PASSWORD: ${POSTGRES_PASSWORD:?Set POSTGRES_PASSWORD}
    volumes:
      - timescaledb_data:/var/lib/postgresql/data
      - ./db/init.sql:/docker-entrypoint-initdb.d/init.sql:ro
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U awet -d awet"]
      interval: 10s
      timeout: 5s
      retries: 10
      start_period: 20s
    logging: *default-logging
    networks:
      - awet

  redis:
    image: redis:7.2
    container_name: redis
    <<: *default-security
    ports:
      - "127.0.0.1:6379:6379"
    command: ["redis-server", "--appendonly", "yes"]
    volumes:
      - redis_data:/data
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 10s
      timeout: 5s
      retries: 10
    logging: *default-logging
    networks:
      - awet

  prometheus:
    image: prom/prometheus:v2.54.1
    container_name: prometheus
    <<: *default-security
    profiles: ["ops"]
    ports:
      - "127.0.0.1:9090:9090"
    volumes:
      - ./prometheus/prometheus.yml:/etc/prometheus/prometheus.yml:ro
      - ./prometheus/alert_rules.yml:/etc/prometheus/alert_rules.yml:ro
      - prometheus_data:/prometheus
    healthcheck:
      test: ["CMD", "wget", "--spider", "-q", "http://localhost:9090/-/healthy"]
      interval: 15s
      timeout: 5s
      retries: 6
    logging: *default-logging
    networks:
      - awet

  grafana:
    image: grafana/grafana:11.1.0
    container_name: grafana
    <<: *default-security
    profiles: ["ops"]
    ports:
      - "127.0.0.1:3000:3000"
    environment:
      GF_SECURITY_ADMIN_PASSWORD: ${GRAFANA_ADMIN_PASSWORD:?Set GRAFANA_ADMIN_PASSWORD}
      GF_USERS_ALLOW_SIGN_UP: "false"
    volumes:
      - ./grafana/provisioning:/etc/grafana/provisioning:ro
      - grafana_data:/var/lib/grafana
    healthcheck:
      test: ["CMD", "wget", "--spider", "-q", "http://localhost:3000/api/health"]
      interval: 15s
      timeout: 5s
      retries: 6
    logging: *default-logging
    networks:
      - awet

  alertmanager:
    image: prom/alertmanager:v0.27.0
    container_name: alertmanager
    <<: *default-security
    profiles: ["ops"]
    ports:
      - "127.0.0.1:9093:9093"
    command: ["--config.file=/etc/alertmanager/config.yml", "--storage.path=/alertmanager"]
    volumes:
      - ./alertmanager/config.yml:/etc/alertmanager/config.yml:ro
      - alertmanager_data:/alertmanager
    healthcheck:
      test: ["CMD", "wget", "--spider", "-q", "http://localhost:9093/-/healthy"]
      interval: 15s
      timeout: 5s
      retries: 6
    logging: *default-logging
    networks:
      - awet

  superagi-postgres:
    image: postgres:15
    container_name: superagi-postgres
    <<: *default-security
    profiles: ["superagi"]
    environment:
      POSTGRES_USER: superagi
      POSTGRES_PASSWORD: ${SUPERAGI_POSTGRES_PASSWORD:?Set SUPERAGI_POSTGRES_PASSWORD}
      POSTGRES_DB: superagi
    volumes:
      - superagi_postgres_data:/var/lib/postgresql/data
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U superagi -d superagi"]
      interval: 10s
      timeout: 5s
      retries: 10
    logging: *default-logging
    networks:
      - awet

  superagi-redis:
    image: redis/redis-stack-server:latest
    container_name: superagi-redis
    <<: *default-security
    profiles: ["superagi"]
    volumes:
      - superagi_redis_data:/data
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 10s
      timeout: 5s
      retries: 10
    logging: *default-logging
    networks:
      - awet

  superagi-backend:
    build:
      context: ./superagi
      dockerfile: Dockerfile
    container_name: superagi-backend
    <<: *default-security
    profiles: ["superagi"]
    depends_on:
      superagi-redis:
        condition: service_healthy
      superagi-postgres:
        condition: service_healthy
      kafka:
        condition: service_healthy
      timescaledb:
        condition: service_healthy
      schema-registry:
        condition: service_healthy
    environment:
      OPENAI_API_KEY: ${OPENAI_API_KEY:-ollama-local}
      ANTHROPIC_API_KEY: ${ANTHROPIC_API_KEY:-}
      OPENAI_API_BASE: ${OPENAI_API_BASE:-http://host.docker.internal:11434/v1}
      LLM_BASE_URL: ${LLM_BASE_URL:-http://host.docker.internal:11434/v1}
      LLM_MODEL: ${LLM_MODEL:-llama3.2:3b}
      POSTGRES_USER: superagi
      POSTGRES_PASSWORD: ${SUPERAGI_POSTGRES_PASSWORD:?Set SUPERAGI_POSTGRES_PASSWORD}
      POSTGRES_DB: superagi
      POSTGRES_HOST: superagi-postgres
      REDIS_HOST: superagi-redis
      REDIS_PORT: 6379
      AWET_KAFKA_BOOTSTRAP: kafka:29092
      AWET_SCHEMA_REGISTRY: http://schema-registry:8081
      AWET_TIMESCALE_HOST: timescaledb
      AWET_TIMESCALE_PORT: 5432
      AWET_TIMESCALE_USER: awet
      AWET_TIMESCALE_PASSWORD: ${POSTGRES_PASSWORD:?Set POSTGRES_PASSWORD}
      AWET_TIMESCALE_DB: awet
    extra_hosts:
      - "host.docker.internal:host-gateway"
    volumes:
      - ./superagi/workspace:/app/workspace
      - ./execution:/app/awet_tools/execution:ro
      - ./directives:/app/awet_tools/directives:ro
      - ./config:/app/awet_tools/config:ro
      - ./src:/app/awet_tools/src:ro
      - ./.tmp:/app/awet_tools/.tmp
      - ./superagi/patches/openai_ollama_compat.py:/app/superagi/llms/openai.py:ro
    ports:
      - "127.0.0.1:8100:8001"
    command: ["python", "-m", "uvicorn", "main:app", "--host", "0.0.0.0", "--port", "8001"]
    healthcheck:
      test: ["CMD", "wget", "--spider", "-q", "http://localhost:8001/health"]
      interval: 20s
      timeout: 5s
      retries: 10
      start_period: 40s
    logging: *default-logging
    networks:
      - awet

  superagi-celery:
    build:
      context: ./superagi
      dockerfile: Dockerfile
    container_name: superagi-celery
    <<: *default-security
    profiles: ["superagi"]
    depends_on:
      superagi-backend:
        condition: service_healthy
      superagi-redis:
        condition: service_healthy
      superagi-postgres:
        condition: service_healthy
    environment:
      OPENAI_API_KEY: ${OPENAI_API_KEY:-ollama-local}
      ANTHROPIC_API_KEY: ${ANTHROPIC_API_KEY:-}
      OPENAI_API_BASE: ${OPENAI_API_BASE:-http://host.docker.internal:11434/v1}
      POSTGRES_USER: superagi
      POSTGRES_PASSWORD: ${SUPERAGI_POSTGRES_PASSWORD:?Set SUPERAGI_POSTGRES_PASSWORD}
      POSTGRES_DB: superagi
      POSTGRES_HOST: superagi-postgres
      REDIS_HOST: superagi-redis
      REDIS_PORT: 6379
      AWET_KAFKA_BOOTSTRAP: kafka:29092
      AWET_SCHEMA_REGISTRY: http://schema-registry:8081
      AWET_TIMESCALE_HOST: timescaledb
      AWET_TIMESCALE_PORT: 5432
      AWET_TIMESCALE_USER: awet
      AWET_TIMESCALE_PASSWORD: ${POSTGRES_PASSWORD:?Set POSTGRES_PASSWORD}
      AWET_TIMESCALE_DB: awet
    extra_hosts:
      - "host.docker.internal:host-gateway"
    volumes:
      - ./superagi/workspace:/app/workspace
      - ./execution:/app/awet_tools/execution:ro
      - ./directives:/app/awet_tools/directives:ro
      - ./.tmp:/app/awet_tools/.tmp
      - ./superagi/patches/openai_ollama_compat.py:/app/superagi/llms/openai.py:ro
    command: ["celery", "-A", "superagi.worker", "worker", "--loglevel=info"]
    logging: *default-logging
    networks:
      - awet

  superagi-gui:
    build:
      context: ./superagi/gui
      dockerfile: Dockerfile
      args:
        NEXT_PUBLIC_API_BASE_URL: /api
    container_name: superagi-gui
    <<: *default-security
    profiles: ["superagi"]
    depends_on:
      superagi-backend:
        condition: service_healthy
    logging: *default-logging
    networks:
      - awet

  superagi-proxy:
    image: nginx:stable-alpine
    container_name: superagi-proxy
    <<: *default-security
    profiles: ["superagi"]
    depends_on:
      superagi-backend:
        condition: service_healthy
      superagi-gui:
        condition: service_started
    ports:
      - "127.0.0.1:3001:80"
    volumes:
      - ./superagi/nginx/default.conf:/etc/nginx/conf.d/default.conf:ro
    healthcheck:
      test: ["CMD", "wget", "--spider", "-q", "http://localhost"]
      interval: 20s
      timeout: 5s
      retries: 10
    logging: *default-logging
    networks:
      - awet

  awet-reconciler:
    image: ${AWET_RUNTIME_IMAGE:-python:3.11-slim}
    container_name: awet-reconciler
    <<: *default-security
    depends_on:
      timescaledb:
        condition: service_healthy
      kafka:
        condition: service_healthy
      schema-registry:
        condition: service_healthy
    environment:
      DATABASE_URL: postgresql://awet:${POSTGRES_PASSWORD:?Set POSTGRES_PASSWORD}@timescaledb:5432/awet
      ALPACA_API_KEY: ${ALPACA_API_KEY:?Set ALPACA_API_KEY}
      ALPACA_API_SECRET: ${ALPACA_API_SECRET:?Set ALPACA_API_SECRET}
      ALPACA_PAPER: ${ALPACA_PAPER:-true}
      PYTHONUNBUFFERED: "1"
      PIP_DISABLE_PIP_VERSION_CHECK: "1"
      TZ: America/New_York
    volumes:
      - .:/app:ro
      - ./logs:/app/logs
    working_dir: /app
    command: >
      bash -c "pip install -q --no-cache-dir asyncpg structlog httpx pytz &&
               python scripts/reconcile_scheduler.py --watch"
    logging: *default-logging
    networks:
      - awet

  awet-eod:
    image: ${AWET_RUNTIME_IMAGE:-python:3.11-slim}
    container_name: awet-eod
    <<: *default-security
    profiles: ["eod"]
    depends_on:
      timescaledb:
        condition: service_healthy
      kafka:
        condition: service_healthy
      schema-registry:
        condition: service_healthy
    environment:
      DATABASE_URL: postgresql://awet:${POSTGRES_PASSWORD:?Set POSTGRES_PASSWORD}@timescaledb:5432/awet
      ALPACA_API_KEY: ${ALPACA_API_KEY:?Set ALPACA_API_KEY}
      ALPACA_API_SECRET: ${ALPACA_API_SECRET:?Set ALPACA_API_SECRET}
      ALPACA_PAPER: ${ALPACA_PAPER:-true}
      PYTHONUNBUFFERED: "1"
      PIP_DISABLE_PIP_VERSION_CHECK: "1"
      TZ: America/New_York
    volumes:
      - .:/app:ro
      - ./logs:/app/logs
    working_dir: /app
    command: >
      bash -c "pip install -q --no-cache-dir asyncpg structlog httpx pytz &&
               python scripts/reconcile_scheduler.py --eod"
    logging: *default-logging
    networks:
      - awet

networks:
  awet:
    driver: bridge

volumes:
  kafka_data:
  timescaledb_data:
  redis_data:
  prometheus_data:
  grafana_data:
  alertmanager_data:
  superagi_postgres_data:
  superagi_redis_data:
