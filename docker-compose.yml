services:
  kafka:
    image: confluentinc/cp-kafka:7.6.1
    container_name: kafka
    restart: unless-stopped
    ports:
      - "9092:9092"
      - "9101:9101"
    environment:
      KAFKA_NODE_ID: 1
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: CONTROLLER:PLAINTEXT,PLAINTEXT:PLAINTEXT,PLAINTEXT_HOST:PLAINTEXT
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka:29092,PLAINTEXT_HOST://localhost:9092
      KAFKA_PROCESS_ROLES: broker,controller
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
      KAFKA_GROUP_INITIAL_REBALANCE_DELAY_MS: 0
      KAFKA_TRANSACTION_STATE_LOG_MIN_ISR: 1
      KAFKA_TRANSACTION_STATE_LOG_REPLICATION_FACTOR: 1
      KAFKA_JMX_PORT: 9101
      KAFKA_JMX_HOSTNAME: localhost
      KAFKA_CONTROLLER_QUORUM_VOTERS: 1@kafka:29093
      KAFKA_LISTENERS: PLAINTEXT://kafka:29092,CONTROLLER://kafka:29093,PLAINTEXT_HOST://0.0.0.0:9092
      KAFKA_INTER_BROKER_LISTENER_NAME: PLAINTEXT
      KAFKA_CONTROLLER_LISTENER_NAMES: CONTROLLER
      KAFKA_LOG_DIRS: /var/lib/kafka/data
      CLUSTER_ID: MkU3OEVBNTcwNTJENDM2Qk
      KAFKA_AUTO_CREATE_TOPICS_ENABLE: "true"
    volumes:
      - kafka_data:/var/lib/kafka/data
    healthcheck:
      test: ["CMD-SHELL", "kafka-broker-api-versions --bootstrap-server localhost:9092 > /dev/null 2>&1"]
      interval: 15s
      timeout: 10s
      retries: 5
      start_period: 30s
    logging:
      driver: json-file
      options:
        max-size: "10m"
        max-file: "3"
    networks:
      - awet

  schema-registry:
    image: confluentinc/cp-schema-registry:7.6.1
    container_name: schema-registry
    restart: unless-stopped
    depends_on:
      kafka:
        condition: service_healthy
    ports:
      - "8081:8081"
    environment:
      SCHEMA_REGISTRY_KAFKASTORE_BOOTSTRAP_SERVERS: kafka:29092
      SCHEMA_REGISTRY_HOST_NAME: schema-registry
      SCHEMA_REGISTRY_LISTENERS: http://0.0.0.0:8081
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8081/subjects"]
      interval: 15s
      timeout: 5s
      retries: 5
      start_period: 15s
    logging:
      driver: json-file
      options:
        max-size: "10m"
        max-file: "3"
    networks:
      - awet

  kafka-ui:
    image: provectuslabs/kafka-ui:v0.7.2
    container_name: kafka-ui
    depends_on:
      - kafka
      - schema-registry
    ports:
      - "${KAFKA_UI_PORT:-8080}:8080"
    environment:
      KAFKA_CLUSTERS_0_NAME: awet
      KAFKA_CLUSTERS_0_BOOTSTRAPSERVERS: kafka:29092
      KAFKA_CLUSTERS_0_SCHEMAREGISTRY: http://schema-registry:8081
    networks:
      - awet

  timescaledb:
    image: timescale/timescaledb:2.13.1-pg15
    container_name: timescaledb
    restart: unless-stopped
    ports:
      - "5433:5432"
    environment:
      - POSTGRES_DB=awet
      - POSTGRES_USER=awet
      - POSTGRES_PASSWORD=${POSTGRES_PASSWORD:-awet}
    volumes:
      - timescaledb_data:/var/lib/postgresql/data
      - ./db/init.sql:/docker-entrypoint-initdb.d/init.sql:ro
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U awet -d awet"]
      interval: 10s
      timeout: 5s
      retries: 5
      start_period: 15s
    logging:
      driver: json-file
      options:
        max-size: "10m"
        max-file: "3"
    networks:
      - awet

  redis:
    image: redis:7.2
    container_name: redis
    restart: unless-stopped
    ports:
      - "6379:6379"
    volumes:
      - redis_data:/data
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 10s
      timeout: 5s
      retries: 5
    logging:
      driver: json-file
      options:
        max-size: "10m"
        max-file: "3"
    networks:
      - awet

  prometheus:
    image: prom/prometheus:v2.54.1
    container_name: prometheus
    restart: unless-stopped
    ports:
      - "9090:9090"
    volumes:
      - ./prometheus/prometheus.yml:/etc/prometheus/prometheus.yml:ro
      - ./prometheus/alert_rules.yml:/etc/prometheus/alert_rules.yml:ro
      - prometheus_data:/prometheus
    healthcheck:
      test: ["CMD", "wget", "--spider", "-q", "http://localhost:9090/-/healthy"]
      interval: 15s
      timeout: 5s
      retries: 3
    logging:
      driver: json-file
      options:
        max-size: "10m"
        max-file: "3"
    networks:
      - awet

  grafana:
    image: grafana/grafana:11.1.0
    container_name: grafana
    restart: unless-stopped
    ports:
      - "3000:3000"
    volumes:
      - ./grafana/provisioning:/etc/grafana/provisioning:ro
      - grafana_data:/var/lib/grafana
    healthcheck:
      test: ["CMD", "wget", "--spider", "-q", "http://localhost:3000/api/health"]
      interval: 15s
      timeout: 5s
      retries: 3
    logging:
      driver: json-file
      options:
        max-size: "10m"
        max-file: "3"
    networks:
      - awet

  alertmanager:
    image: prom/alertmanager:v0.27.0
    container_name: alertmanager
    restart: unless-stopped
    ports:
      - "9093:9093"
    volumes:
      - ./alertmanager/config.yml:/etc/alertmanager/config.yml:ro
    logging:
      driver: json-file
      options:
        max-size: "10m"
        max-file: "3"
    networks:
      - awet

  # ============================================
  # SuperAGI - Autonomous AI Agent Orchestrator
  # ============================================
  superagi-backend:
    build:
      context: ./superagi
      dockerfile: Dockerfile
    container_name: superagi-backend
    depends_on:
      - superagi-redis
      - superagi-postgres
      - kafka
      - timescaledb
    environment:
      - OPENAI_API_KEY=${OPENAI_API_KEY:-ollama-local}
      - ANTHROPIC_API_KEY=${ANTHROPIC_API_KEY:-}
      - POSTGRES_USER=superagi
      - POSTGRES_PASSWORD=superagi
      - POSTGRES_DB=superagi
      - POSTGRES_HOST=superagi-postgres
      - REDIS_HOST=superagi-redis
      - REDIS_PORT=6379
      # AWET Pipeline connections
      - AWET_KAFKA_BOOTSTRAP=kafka:29092
      - AWET_SCHEMA_REGISTRY=http://schema-registry:8081
      - AWET_TIMESCALE_HOST=timescaledb
      - AWET_TIMESCALE_PORT=5432
      - AWET_TIMESCALE_USER=awet
      - AWET_TIMESCALE_PASSWORD=awet
      - AWET_TIMESCALE_DB=awet
      # Local LLM config - Ollama on host with GPU acceleration
      - LLM_BASE_URL=http://host.docker.internal:11434/v1
      - LLM_MODEL=llama3.2:3b
      # OpenAI API base - points to host Ollama for GPU-accelerated inference
      - OPENAI_API_BASE=http://host.docker.internal:11434/v1
    volumes:
      - ./superagi/workspace:/app/workspace
      - ./execution:/app/awet_tools/execution:ro
      - ./directives:/app/awet_tools/directives:ro
      - ./config:/app/awet_tools/config:ro
      - ./src:/app/awet_tools/src:ro
      - ./.tmp:/app/awet_tools/.tmp
      # Ollama compatibility patch for OpenAI SDK
      - ./superagi/patches/openai_ollama_compat.py:/app/superagi/llms/openai.py:ro
    ports:
      - "8100:8001"
    networks:
      - awet
    command: ["python", "-m", "uvicorn", "main:app", "--host", "0.0.0.0", "--port", "8001"]

  superagi-celery:
    build:
      context: ./superagi
      dockerfile: Dockerfile
    container_name: superagi-celery
    depends_on:
      - superagi-redis
      - superagi-postgres
      - superagi-backend
    environment:
      - OPENAI_API_KEY=${OPENAI_API_KEY:-ollama-local}
      - ANTHROPIC_API_KEY=${ANTHROPIC_API_KEY:-}
      - POSTGRES_USER=superagi
      - POSTGRES_PASSWORD=superagi
      - POSTGRES_DB=superagi
      - POSTGRES_HOST=superagi-postgres
      - REDIS_HOST=superagi-redis
      - REDIS_PORT=6379
      - AWET_KAFKA_BOOTSTRAP=kafka:29092
      - AWET_SCHEMA_REGISTRY=http://schema-registry:8081
      - AWET_TIMESCALE_HOST=timescaledb
      - AWET_TIMESCALE_PORT=5432
      # OpenAI API base - points to host Ollama for GPU-accelerated inference
      - OPENAI_API_BASE=http://host.docker.internal:11434/v1
    volumes:
      - ./superagi/workspace:/app/workspace
      - ./execution:/app/awet_tools/execution:ro
      - ./directives:/app/awet_tools/directives:ro
      - ./.tmp:/app/awet_tools/.tmp
      # Ollama compatibility patch for OpenAI SDK
      - ./superagi/patches/openai_ollama_compat.py:/app/superagi/llms/openai.py:ro
    networks:
      - awet
    command: ["celery", "-A", "superagi.worker", "worker", "--loglevel=info"]

  superagi-gui:
    build:
      context: ./superagi/gui
      dockerfile: Dockerfile
      args:
        NEXT_PUBLIC_API_BASE_URL: "/api"
    container_name: superagi-gui
    depends_on:
      - superagi-backend
    networks:
      - awet

  superagi-proxy:
    image: nginx:stable-alpine
    container_name: superagi-proxy
    ports:
      - "3001:80"
    depends_on:
      - superagi-backend
      - superagi-gui
    volumes:
      - ./superagi/nginx/default.conf:/etc/nginx/conf.d/default.conf:ro
    networks:
      - awet

  superagi-redis:
    image: redis/redis-stack-server:latest
    container_name: superagi-redis
    volumes:
      - superagi_redis_data:/data
    networks:
      - awet

  superagi-postgres:
    image: postgres:15
    container_name: superagi-postgres
    environment:
      - POSTGRES_USER=superagi
      - POSTGRES_PASSWORD=superagi
      - POSTGRES_DB=superagi
    volumes:
      - superagi_postgres_data:/var/lib/postgresql/data/
    networks:
      - awet

  # ============================================
  # AWET Automated Reconciliation & PnL
  # ============================================
  
  # Continuous order reconciliation during market hours
  awet-reconciler:
    image: python:3.11-slim
    container_name: awet-reconciler
    depends_on:
      - timescaledb
      - kafka
      - schema-registry
    environment:
      - DATABASE_URL=postgresql://awet:awet@timescaledb:5432/awet
      - ALPACA_API_KEY=${ALPACA_API_KEY:-}
      - ALPACA_SECRET_KEY=${ALPACA_SECRET_KEY:-${ALPACA_API_SECRET:-}}
      - ALPACA_API_SECRET=${ALPACA_API_SECRET:-${ALPACA_SECRET_KEY:-}}
      - ALPACA_PAPER=${ALPACA_PAPER:-true}
      - PYTHONUNBUFFERED=1
      - TZ=America/New_York
    volumes:
      - .:/app:ro
      - ./logs:/app/logs
    working_dir: /app
    command: >
      bash -c "pip install -q asyncpg structlog httpx pytz prometheus-client fastapi &&
               python scripts/reconcile_scheduler.py --watch"
    restart: unless-stopped
    networks:
      - awet
    logging:
      driver: json-file
      options:
        max-size: "10m"
        max-file: "3"

  # End-of-day job (manual trigger or scheduled)
  awet-eod:
    image: python:3.11-slim
    container_name: awet-eod
    depends_on:
      - timescaledb
      - kafka
      - schema-registry
    environment:
      - DATABASE_URL=postgresql://awet:awet@timescaledb:5432/awet
      - ALPACA_API_KEY=${ALPACA_API_KEY:-}
      - ALPACA_SECRET_KEY=${ALPACA_SECRET_KEY:-${ALPACA_API_SECRET:-}}
      - ALPACA_API_SECRET=${ALPACA_API_SECRET:-${ALPACA_SECRET_KEY:-}}
      - ALPACA_PAPER=${ALPACA_PAPER:-true}
      - PYTHONUNBUFFERED=1
      - TZ=America/New_York
    volumes:
      - .:/app:ro
      - ./logs:/app/logs
    working_dir: /app
    command: >
      bash -c "pip install -q asyncpg structlog httpx pytz prometheus-client fastapi &&
               python scripts/reconcile_scheduler.py --eod"
    profiles:
      - eod
    networks:
      - awet

  # ── Telegram Bot ────────────────────────────────────────────────────────────
  telegram-bot:
    build:
      context: ./services/telegram-bot
      dockerfile: Dockerfile
    image: awet/telegram-bot:latest
    container_name: telegram-bot
    restart: unless-stopped
    depends_on:
      - kb-query
    environment:
      - TELEGRAM_BOT_TOKEN=${TELEGRAM_BOT_TOKEN}
      - KB_QUERY_BASE_URL=http://kb-query:8000
      - HTTP_TIMEOUT_SEC=${TELEGRAM_HTTP_TIMEOUT_SEC:-5}
      - HTTP_MAX_RETRIES=${TELEGRAM_HTTP_MAX_RETRIES:-3}
      - DEFAULT_LIMIT=${TELEGRAM_DEFAULT_LIMIT:-5}
      - MAX_LIMIT=${TELEGRAM_MAX_LIMIT:-50}
      - LOG_LEVEL=${LOG_LEVEL:-INFO}
      - METRICS_PORT=9200
      - STATE_FILE=/var/lib/telegram-bot/state.json
      - RATE_LIMIT_MESSAGES_PER_SEC=${TELEGRAM_RATE_LIMIT:-1.0}
      # LLM: set LLM_PROVIDER=anthropic|kimi|openai and LLM_API_KEY
      - LLM_PROVIDER=${LLM_PROVIDER:-anthropic}
      - LLM_API_KEY=${LLM_API_KEY:-}
      - LLM_MODEL=${LLM_MODEL:-}
      - LLM_TIMEOUT_SEC=${LLM_TIMEOUT_SEC:-30}
      - LLM_RAG_LIMIT=${LLM_RAG_LIMIT:-5}
    volumes:
      - telegram_bot_state:/var/lib/telegram-bot
    ports:
      - "${TELEGRAM_METRICS_PORT:-9200}:9200"
    networks:
      - awet
    healthcheck:
      test: ["CMD", "python", "-c", "import urllib.request; urllib.request.urlopen('http://localhost:9200/healthz')"]
      interval: 30s
      timeout: 5s
      retries: 3
    profiles:
      - telegram

networks:
  awet:
    driver: bridge

volumes:
  kafka_data:
  telegram_bot_state:
  timescaledb_data:
  redis_data:
  prometheus_data:
  grafana_data:
  superagi_postgres_data:
  superagi_redis_data:
