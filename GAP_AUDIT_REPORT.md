# GAP AUDIT REPORT: AWET Trading Pipeline

**Date**: January 15, 2026  
**Auditor**: GitHub Copilot  
**Repo**: /home/kironix/Awet

---

## Executive Summary

The codebase has **substantial infrastructure in place** but has **critical gaps** preventing true end-to-end operation. Below is each requirement with status, gaps, and minimal patch plans.

---

## 1. Kafka KRaft + Schema Registry + Avro Schemas

**Status: ‚úÖ COMPLETE**

| Component | Status | Location |
|-----------|--------|----------|
| Kafka KRaft | ‚úÖ | docker-compose.yml:1-27 - `KAFKA_PROCESS_ROLES: broker,controller`, `CLUSTER_ID` set |
| Schema Registry | ‚úÖ | docker-compose.yml:29-41 |
| Avro Schemas | ‚úÖ | src/schemas/ - 5 schemas defined |

**No gaps.**

---

## 2. correlation_id + idempotency End-to-End

**Status: ‚ö†Ô∏è PARTIAL - 2 GAPS**

| Component | Status | Location |
|-----------|--------|----------|
| BaseEvent fields | ‚úÖ | src/models/base.py:10-22 - All required fields present |
| correlation_id propagation | ‚úÖ | All agents call `set_correlation_id()` |
| Idempotency check | ‚úÖ | src/audit/trail_logger.py:38-46 `is_duplicate()` |

### GAP 2.1: No test enforcing ALL events have required fields

- **File**: tests/unit/test_event_validation.py:1-14
- **Issue**: Test only checks one event type fails without fields, not that all agents emit valid events
- **Patch Plan**: Add integration test that validates emitted events from each agent have: `event_id`, `correlation_id`, `idempotency_key`, `symbol`, `ts`, `schema_version`, `source`

### GAP 2.2: Backfill scripts don't track checkpoint/resume in DB

- **File**: execution/backfill_polygon.py:1-200
- **Issue**: No checkpoint table for resumable backfill; restart = start from scratch
- **Patch Plan**: Add `backfill_checkpoints` table + checkpoint after each file processed

---

## 3. Prometheus Metrics per Agent + /health Endpoints

**Status: ‚ö†Ô∏è PARTIAL - 2 GAPS**

| Component | Status | Location |
|-----------|--------|----------|
| BaseAgent /health | ‚úÖ | src/agents/base_agent.py:27 |
| BaseAgent /metrics | ‚úÖ | src/agents/base_agent.py:28 |
| Prometheus scrape config | ‚úÖ | prometheus/prometheus.yml:1-14 |
| EVENTS_PROCESSED counter | ‚úÖ | src/monitoring/metrics.py:8-13 |
| EVENT_LATENCY histogram | ‚úÖ | src/monitoring/metrics.py:22-27 |

### GAP 3.1: WatchtowerAgent doesn't track Kafka consumer lag

- **File**: src/agents/watchtower_agent.py:1-30
- **Issue**: Only emits heartbeat, no actual Kafka lag metrics via `kafka-consumer-groups --describe`
- **Patch Plan**: Add `CONSUMER_LAG` Gauge metric, poll Kafka admin API or shell out to `kafka-consumer-groups`

### GAP 3.2: Grafana dashboard is empty placeholder

- **File**: grafana/provisioning/dashboards/empty.json:1-8
- **Issue**: No actual panels for throughput, latency, lag
- **Patch Plan**: Create real dashboard JSON with panels for `events_processed_total`, `event_latency_seconds`, `kafka_consumer_lag`

---

## 4. TimescaleDB Audit Trail

**Status: ‚úÖ COMPLETE**

| Component | Status | Location |
|-----------|--------|----------|
| audit_events table | ‚úÖ | db/init.sql:146-175 - Hypertable with all fields |
| AuditTrailLogger | ‚úÖ | src/audit/trail_logger.py:1-70 |
| All agents write audit | ‚úÖ | Each agent calls `await self.audit.write_event()` |

**No gaps.**

---

## 5. Retry + Circuit Breaker

**Status: ‚úÖ COMPLETE**

| Component | Status | Location |
|-----------|--------|----------|
| retry_async() | ‚úÖ | src/core/retry.py:1-28 - exponential backoff + jitter |
| CircuitBreaker | ‚úÖ | src/core/circuit_breaker.py:1-42 |
| Usage in providers | ‚úÖ | src/market_data/providers.py:44,77-97 |
| Tests | ‚úÖ | tests/unit/test_retry.py, tests/unit/test_circuit_breaker.py |

**No gaps.**

---

## 6. Approval Gate for ExecutionAgent

**Status: ‚úÖ COMPLETE**

| Component | Status | Location |
|-----------|--------|----------|
| Approval file check | ‚úÖ | src/agents/execution_agent.py:61-62 |
| Config for approval path | ‚úÖ | config/app.yaml:12 |
| Blocked status in event | ‚úÖ | src/agents/execution_agent.py:63-64 |
| execution.blocked topic | ‚úÖ | src/streaming/topics.py - EXECUTION_BLOCKED constant |
| make approve/revoke | ‚úÖ | Makefile - approve and revoke targets |

### ~~GAP 6.1~~ ‚úÖ FIXED: Blocked events now go to `execution.blocked` topic

- **Fixed in**: src/streaming/topics.py, src/agents/execution_agent.py
- **Solution**: Added `EXECUTION_BLOCKED` topic constant, execution_agent publishes to separate topic based on approval status

### ~~GAP 6.2~~ ‚úÖ FIXED: `make approve` / `make revoke` targets added

- **Fixed in**: Makefile
- **Solution**: Added targets:
```makefile
approve:
	@mkdir -p .tmp && touch .tmp/APPROVE_EXECUTION
	@echo "‚úÖ Execution APPROVED"
revoke:
	@rm -f .tmp/APPROVE_EXECUTION
	@echo "üö´ Execution REVOKED"
```

---

## 7. TFT Real Training + ONNX Export + Model Registry + PredictionAgent Loads Green

**Status: ‚ö†Ô∏è MOSTLY COMPLETE - 1 GAP**

| Component | Status | Location |
|-----------|--------|----------|
| TFT model | ‚úÖ | src/ml/tft/model.py |
| Training from DB | ‚úÖ | src/ml/train.py:45-150 |
| ONNX export | ‚úÖ | src/ml/tft/model.py `export_to_onnx()` |
| Model registry | ‚úÖ | src/ml/registry.py:1-338 |
| CLI commands | ‚úÖ | src/ml/train.py - train/export/promote/list |
| PredictionAgent loads green | ‚úÖ | src/prediction/engine.py:325-340 via `get_green_model_path()` |
| Auto-detect lookback | ‚úÖ | src/ml/onnx_engine.py:118-121 |

### GAP 7.1: PredictionAgent doesn't hot-reload model without restart

- **File**: src/prediction/engine.py:242-258
- **Issue**: Model loaded once at warmup, no periodic check for new green model
- **Patch Plan**: Add background task in `ONNXPredictionEngine` that calls `reload_if_needed()` every N seconds

---

## 8. Risk Engine Real Gates (Not Placeholder)

**Status: ‚ö†Ô∏è MOSTLY COMPLETE - 1 GAP**

| Component | Status | Location |
|-----------|--------|----------|
| Position sizing | ‚úÖ | src/risk/engine.py:143-145 - max_position_pct |
| Max exposure per ticker | ‚úÖ | src/risk/engine.py:143 |
| Daily loss limit | ‚úÖ | src/risk/engine.py:119-121 |
| CVaR placeholder | ‚úÖ | src/risk/engine.py:159-180 `_calculate_cvar()` |
| Reject path to risk.rejected | ‚úÖ | src/agents/risk_agent.py:98-100 |
| Audit every decision | ‚úÖ | src/agents/risk_agent.py:101 |

### GAP 8.1: Risk limits not loaded from config/limits.yaml

- **File**: src/risk/engine.py:100-106
- **Issue**: Only loads from env vars, ignores config/limits.yaml
- **Patch Plan**: Add YAML loader in `_load_config()` to read from `config/limits.yaml`

---

## 9. Backfill Scripts (Polygon + Reddit)

**Status: ‚ö†Ô∏è PARTIAL - 3 GAPS**

| Component | Status | Location |
|-----------|--------|----------|
| Polygon backfill | ‚úÖ | execution/backfill_polygon.py |
| Reddit backfill | ‚ö†Ô∏è | execution/backfill_reddit.py - exists but no schema |
| Avro validation | ‚úÖ | Uses AvroSerializer |

### GAP 9.1: No `reddit.raw` Avro schema

- **File**: src/schemas/
- **Issue**: Reddit backfill references schema that doesn't exist
- **Patch Plan**: Create `src/schemas/reddit_raw.avsc`

### GAP 9.2: No checkpoint table for resumable backfill

- **File**: db/init.sql
- **Issue**: Missing `backfill_checkpoints` table
- **Patch Plan**: Add table with `(source, filename, last_offset, completed_at)`

### GAP 9.3: Reddit backfill uses wrong paths

- **File**: Makefile:55-63
- **Issue**: Uses `/home/kironix/train/reddit/submissions` but user has `submissions/*` subdirs
- **Patch Plan**: Update loader to handle subdirectory structure

---

## 10. Database Schema

**Status: ‚úÖ COMPLETE**

| Table | Status | Location |
|-------|--------|----------|
| audit_events | ‚úÖ | db/init.sql:146-175 |
| features_tft | ‚úÖ | db/init.sql:49-94 |
| predictions_tft | ‚úÖ | db/init.sql:96-122 |
| paper_trades | ‚úÖ | db/init.sql:124-145 |
| models_registry | ‚úÖ | db/init.sql:181-200 |
| risk_decisions | ‚úÖ | db/init.sql - hypertable |
| backfill_checkpoints | ‚úÖ | db/init.sql |

### ~~GAP 10.1~~ ‚úÖ FIXED: `risk_decisions` table added

- **Fixed in**: db/init.sql
- **Solution**: Added `risk_decisions` hypertable with: `ticker, ts, approved, reason, limits_snapshot JSONB`

### ~~GAP 10.2~~ ‚úÖ FIXED: `backfill_checkpoints` table added

- **Fixed in**: db/init.sql
- **Solution**: Added table with: `source, filename, last_offset, records_processed, updated_at`

---

## 11. Demo / End-to-End Runnable

**Status: ‚ö†Ô∏è PARTIAL - 1 GAP**

### ~~GAP 11.1~~ ‚úÖ FIXED: `make demo` now verifies full message flow

- **Fixed in**: execution/demo.py
- **Solution**: Complete rewrite - verifies events flow through: market.raw ‚Üí market.engineered ‚Üí predictions.tft ‚Üí risk.approved ‚Üí execution.completed/blocked

### ~~GAP 11.2~~ ‚úÖ FIXED: Demo generates synthetic data

- **Fixed in**: execution/demo.py
- **Solution**: Demo now generates 15 synthetic MarketRawEvent messages (5 per ticker: AAPL, MSFT, NVDA) with deterministic idempotency keys

### GAP 11.3: README doesn't have complete runbook

- **File**: README.md
- **Issue**: Missing exact commands for fresh machine setup
- **Patch Plan**: Rewrite with step-by-step: setup ‚Üí up ‚Üí backfill ‚Üí train ‚Üí promote ‚Üí approve ‚Üí demo

---

## Summary: Priority Order for Fixes

| Priority | Requirement | Gaps | Effort | Status |
|----------|-------------|------|--------|--------|
| ~~üî¥ P0~~ | ~~DB Schema~~ | ~~2 tables~~ | ~~Small~~ | ‚úÖ DONE |
| ~~üî¥ P0~~ | ~~Backfill checkpoints~~ | ~~1 table + code~~ | ~~Medium~~ | ‚úÖ DONE |
| ~~üü° P1~~ | ~~Make demo runnable~~ | ~~3 fixes~~ | ~~Medium~~ | ‚úÖ DONE |
| ~~üü° P1~~ | ~~Approval gate `make approve/revoke`~~ | ~~Makefile~~ | ~~Tiny~~ | ‚úÖ DONE |
| ~~üü° P1~~ | ~~Risk loads from YAML~~ | ~~1 function~~ | ~~Small~~ | ‚úÖ DONE |
| ~~üü¢ P2~~ | ~~Watchtower lag metrics~~ | ~~New feature~~ | ~~Medium~~ | ‚úÖ DONE |
| ~~üü¢ P2~~ | ~~Grafana dashboard~~ | ~~JSON~~ | ~~Medium~~ | ‚úÖ DONE |
| ~~üü¢ P2~~ | ~~Hot-reload models~~ | ~~Background task~~ | ~~Small~~ | ‚úÖ DONE |
| ~~üü¢ P2~~ | ~~Event validation tests~~ | ~~Tests~~ | ~~Small~~ | ‚úÖ DONE |
| ~~üü¢ P3~~ | ~~Reddit schema + paths~~ | ~~Schema + loader~~ | ~~Medium~~ | ‚úÖ DONE |

---

## Recommended Execution Order

```
#4 (DB schema) ‚Üí #2 (demo runnable) ‚Üí #3 (backfill) ‚Üí #5 (train) ‚Üí #6 (risk) ‚Üí #7 (execution) ‚Üí #8 (observability) ‚Üí #9 (tests) ‚Üí #10 (README)
```

This ensures:
1. Database tables exist before anything writes to them
2. Demo works end-to-end before adding complexity
3. Training has data to work with
4. Risk/execution gates are enforced
5. Observability proves it works
6. Tests catch regressions
7. README documents final state

---

## Total Gap Count

| Category | Complete | Gaps | Fixed |
|----------|----------|------|-------|
| Kafka + Schema Registry | ‚úÖ | 0 | - |
| correlation_id + idempotency | ‚úÖ | ~~2~~ 0 | **2** |
| Prometheus + /health | ‚úÖ | ~~2~~ 0 | **2** |
| TimescaleDB audit | ‚úÖ | 0 | - |
| Retry + Circuit Breaker | ‚úÖ | 0 | - |
| Approval Gate | ‚úÖ | ~~2~~ 0 | **2** |
| TFT + ONNX + Registry | ‚úÖ | ~~1~~ 0 | **1** |
| Risk Engine | ‚úÖ | ~~1~~ 0 | **1** |
| Backfill Scripts | ‚úÖ | ~~3~~ 0 | **3** |
| Database Schema | ‚úÖ | ~~2~~ 0 | **2** |
| Demo E2E | ‚úÖ | ~~3~~ 0 | **3** |
| **TOTAL** | **11/11** | **0** | **16 FIXED** |

---

## ‚úÖ ALL GAPS FIXED

**Session 3 Fixes (10 gaps):**
- ‚úÖ GAP 2.1: Comprehensive event validation tests
- ‚úÖ GAP 2.2: Backfill checkpoint code (`src/backfill/checkpoint.py`)
- ‚úÖ GAP 3.1: Watchtower Kafka consumer lag metrics
- ‚úÖ GAP 3.2: Real Grafana dashboard (`awet-pipeline.json`)
- ‚úÖ GAP 7.1: Hot-reload models in PredictionAgent
- ‚úÖ GAP 8.1: Risk engine loads from `config/limits.yaml`
- ‚úÖ GAP 9.1: Reddit Avro schema (`src/schemas/reddit_raw.avsc`)
- ‚úÖ GAP 9.2: Reddit backfill uses checkpoints
- ‚úÖ GAP 9.3: Reddit backfill handles subdirectories (`**/*.zst`)
- ‚úÖ GAP 11.3: Complete README runbook

**Previous Sessions (6 gaps):**
- ‚úÖ GAP 10.1: Added `risk_decisions` hypertable
- ‚úÖ GAP 10.2: Added `backfill_checkpoints` table
- ‚úÖ GAP 6.1: Added `execution.blocked` topic
- ‚úÖ GAP 6.2: Added `make approve/revoke` targets
- ‚úÖ GAP 11.1: Demo verifies full message flow
- ‚úÖ GAP 11.2: Demo generates synthetic data

**Verification commands:**
```bash
# Fresh machine setup
make setup && make up

# Run demo in BLOCKED mode
make revoke && make demo   # ‚Üí execution.blocked

# Run demo in APPROVED mode
make approve && make demo  # ‚Üí execution.completed

# Test with resume capability
python execution/backfill_polygon.py --data-dir /path/to/data --resume
python execution/backfill_reddit.py --submissions-dir /path/to/reddit --resume

# View Grafana dashboard
open http://localhost:3000  # awet-pipeline dashboard
```
